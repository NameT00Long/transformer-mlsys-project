"""
ç¿»è¯‘ä»»åŠ¡è®­ç»ƒæ¨¡å—
"""

import os
import sys
import pickle
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from model.full_transformer import Transformer
from data.translation_data import get_dataloaders
import matplotlib.pyplot as plt

# è·å–é¡¹ç›®æ ¹ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = current_dir
if project_root not in sys.path:
    sys.path.append(project_root)

def prepare_vocab_for_saving(vocab, vocab_name):
    """
    å‡†å¤‡è¯è¡¨ä»¥ä¾›ä¿å­˜ï¼Œç¡®ä¿è¯è¡¨æ ¼å¼æ­£ç¡®
    (å·²ä¿®å¤ï¼šæ”¯æŒ token_to_idx å±æ€§å)
    """
    # æ£€æŸ¥è¯è¡¨æ˜¯å¦ä¸ºç©º
    if vocab is None:
        raise ValueError(f"{vocab_name}ä¸ºç©º")
    
    token2idx = None
    idx2token = None

    # 1. æ£€æŸ¥å­—å…¸æ ¼å¼
    if isinstance(vocab, dict):
        token2idx = vocab
        idx2token = {v: k for k, v in vocab.items()}
    
    # 2. æ£€æŸ¥å¸¸è§å¯¹è±¡æ ¼å¼ (token2idx)
    elif hasattr(vocab, 'token2idx') and hasattr(vocab, 'idx2token'):
        token2idx = vocab.token2idx
        idx2token = vocab.idx2token
        
    # 3. [æ–°å¢] æ£€æŸ¥ä½ çš„ Vocab ç±»æ ¼å¼ (token_to_idx)
    elif hasattr(vocab, 'token_to_idx') and hasattr(vocab, 'idx_to_token'):
        print(f"âœ… è¯†åˆ«åˆ° {vocab_name} ä¸º token_to_idx æ ¼å¼")
        token2idx = vocab.token_to_idx
        # æ³¨æ„ï¼šä½ çš„ idx_to_token æ˜¯åˆ—è¡¨ï¼Œä¸ºäº†ç»Ÿä¸€æ ¼å¼ï¼Œæˆ‘ä»¬åœ¨ä¿å­˜æ—¶æŠŠå®ƒè½¬ä¸ºå­—å…¸
        if isinstance(vocab.idx_to_token, list):
            idx2token = {i: t for i, t in enumerate(vocab.idx_to_token)}
        else:
            idx2token = vocab.idx_to_token

    # 4. æ£€æŸ¥ torchtext æ—§ç‰ˆæœ¬æ ¼å¼
    elif hasattr(vocab, 'get_stoi') and hasattr(vocab, 'get_itos'):
        token2idx = vocab.get_stoi()
        idx2token = {i: s for s, i in token2idx.items()}
        
    # 5. åˆ—è¡¨æ ¼å¼
    elif isinstance(vocab, list):
        token2idx = {token: idx for idx, token in enumerate(vocab)}
        idx2token = {idx: token for idx, token in enumerate(vocab)}
    
    # 6. å…œåº•å°è¯•
    else:
        try:
            token2idx = dict(vocab)
            idx2token = {v: k for k, v in token2idx.items()}
        except (TypeError, ValueError):
            print(f"è¯è¡¨ç±»å‹: {type(vocab)}")
            raise ValueError(f"{vocab_name}æ ¼å¼ä¸æ”¯æŒ: {type(vocab)}")
    
    # éªŒè¯æå–ç»“æœ
    if not token2idx or not idx2token:
        raise ValueError(f"{vocab_name}å†…å®¹æå–å¤±è´¥æˆ–ä¸ºç©º")
    
    # æ£€æŸ¥ç‰¹æ®Štoken
    special_tokens = ['<pad>', '<sos>', '<eos>', '<unk>']
    missing_tokens = [token for token in special_tokens if token not in token2idx]
    if missing_tokens:
        print(f"âš ï¸ è­¦å‘Š: {vocab_name}ç¼ºå°‘ç‰¹æ®Štoken: {missing_tokens}")
    
    # è¿”å›æ ‡å‡†æ ¼å¼
    return {'token2idx': token2idx, 'idx2token': idx2token}

def calculate_accuracy(outputs, targets):
    """è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡"""
    _, predicted = torch.max(outputs, dim=2)
    correct = (predicted == targets).float()
    mask = (targets != 0).float()  # å¿½ç•¥padding
    return (correct * mask).sum() / mask.sum()

def train_translation_epoch(model, dataloader, optimizer, criterion, device):
    """è®­ç»ƒç¿»è¯‘æ¨¡å‹ä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    total_accuracy = 0
    
    for batch_idx, (src, tgt) in enumerate(dataloader):
        src, tgt = src.to(device), tgt.to(device)
        
        # ç›®æ ‡è¾“å…¥å’Œç›®æ ‡è¾“å‡º
        tgt_input = tgt[:, :-1]
        tgt_output = tgt[:, 1:]
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        output = model(src, tgt_input)
        
        # è®¡ç®—æŸå¤±
        output = output.reshape(-1, output.size(-1))
        tgt_output = tgt_output.reshape(-1)
        loss = criterion(output, tgt_output)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = calculate_accuracy(
            output.reshape(src.size(0), tgt_input.size(1), -1),
            tgt_output.reshape(src.size(0), tgt_input.size(1))
        )
        
        total_loss += loss.item()
        total_accuracy += accuracy.item()
        
        if batch_idx % 100 == 0:
            print(f"Batch {batch_idx}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}")
    
    return total_loss / len(dataloader), total_accuracy / len(dataloader)

def evaluate_translation(model, dataloader, criterion, device):
    """è¯„ä¼°ç¿»è¯‘æ¨¡å‹"""
    model.eval()
    total_loss = 0
    total_accuracy = 0
    
    with torch.no_grad():
        for src, tgt in dataloader:
            src, tgt = src.to(device), tgt.to(device)
            
            # ç›®æ ‡è¾“å…¥å’Œç›®æ ‡è¾“å‡º
            tgt_input = tgt[:, :-1]
            tgt_output = tgt[:, 1:]
            
            # å‰å‘ä¼ æ’­
            output = model(src, tgt_input)
            
            # è®¡ç®—æŸå¤±
            output = output.reshape(-1, output.size(-1))
            tgt_output = tgt_output.reshape(-1)
            loss = criterion(output, tgt_output)
            
            # è®¡ç®—å‡†ç¡®ç‡
            accuracy = calculate_accuracy(
                output.reshape(src.size(0), tgt_input.size(1), -1),
                tgt_output.reshape(src.size(0), tgt_input.size(1))
            )
            
            total_loss += loss.item()
            total_accuracy += accuracy.item()
    
    return total_loss / len(dataloader), total_accuracy / len(dataloader)

def train_translation_model(params):
    """è®­ç»ƒç¿»è¯‘æ¨¡å‹ä¸»å‡½æ•°"""
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(params['data_dir']):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®ç›®å½• {params['data_dir']}")
        print("è¯·ç¡®ä¿ç¿»è¯‘æ•°æ®é›†å·²ä¸‹è½½å¹¶æ”¾ç½®åœ¨æ­£ç¡®ç›®å½•ä¸­")
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        from data.download_sample_data import prepare_data_for_training
        prepare_data_for_training()
        params['data_dir'] = 'data/multi30k'  # ä½¿ç”¨æ–°çš„æ•°æ®ç›®å½•

    # åŠ è½½ç¿»è¯‘æ•°æ®
    print("ğŸ“¥ åŠ è½½ç¿»è¯‘æ•°æ®...")
    train_loader, val_loader, test_loader, src_vocab, tgt_vocab = get_dataloaders(
        params['data_dir'],
        batch_size=params['batch_size'],
        max_len=params['max_seq_len'],
        src_lang=params['src_lang'],
        tgt_lang=params['tgt_lang']
    )
    
    if train_loader is None:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®")
        return float('inf')
    
    print(f"ğŸ”¤ æºè¯­è¨€è¯æ±‡è¡¨å¤§å°: {len(src_vocab)}")
    print(f"ğŸ”¤ ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°: {len(tgt_vocab)}")
    print(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
    print(f"ğŸ“Š éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
    print(f"ğŸ“Š æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset)}")

    # åˆå§‹åŒ–å®Œæ•´Transformeræ¨¡å‹
    model = Transformer(
        src_vocab_size=len(src_vocab),
        tgt_vocab_size=len(tgt_vocab),
        d_model=params['d_model'],
        num_heads=params['num_heads'],
        d_ff=params['d_model']*4,  # å‰é¦ˆç½‘ç»œç»´åº¦é€šå¸¸æ˜¯d_modelçš„4å€
        num_layers=params['num_layers'],
        max_len=params['max_seq_len'],
        dropout=params['dropout']
    ).to(device)

    print(f"ğŸ“Š ç¿»è¯‘æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ä¼˜åŒ–å™¨ & æŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], betas=(0.9, 0.98), eps=1e-9)
    criterion = nn.CrossEntropyLoss(ignore_index=0)  # å¿½ç•¥å¡«å……å€¼

    # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    for epoch in range(1, params['epochs'] + 1):
        print(f"\nğŸš€ Epoch {epoch}/{params['epochs']}")
        print("-" * 30)

        # è®­ç»ƒ
        train_loss, train_acc = train_translation_epoch(model, train_loader, optimizer, criterion, device)
        print(f"ğŸ“ˆ Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        # éªŒè¯
        val_loss, val_acc = evaluate_translation(model, val_loader, criterion, device)
        print(f"ğŸ“‰ Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        # ä¿å­˜æœ€ä½³æ¨¡å‹å’Œè¯æ±‡è¡¨
        if val_loss < best_loss:
            best_loss = val_loss
            # ä¿å­˜æ¨¡å‹
            torch.save(model.state_dict(), params['model_save_path'])
            
            # å‡†å¤‡è¯è¡¨ä»¥ä¾›ä¿å­˜
        try:
            src_vocab_dict = prepare_vocab_for_saving(src_vocab, "æºè¯­è¨€è¯è¡¨")
            tgt_vocab_dict = prepare_vocab_for_saving(tgt_vocab, "ç›®æ ‡è¯­è¨€è¯è¡¨")
            
            # ä¿å­˜è¯è¡¨åˆ°é¡¹ç›®æ ¹ç›®å½•
            src_vocab_path = os.path.join(project_root, 'src_vocab.pkl')
            tgt_vocab_path = os.path.join(project_root, 'tgt_vocab.pkl')
            
            with open(src_vocab_path, 'wb') as f:
                pickle.dump(src_vocab_dict, f)
            with open(tgt_vocab_path, 'wb') as f:
                pickle.dump(tgt_vocab_dict, f)
            
            print(f"âœ¨ ç¿»è¯‘æ¨¡å‹å’Œè¯æ±‡è¡¨å·²ä¿å­˜ (Val Loss: {val_loss:.4f})")
            print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {params['model_save_path']}")
            print(f"ğŸ“ æºè¯­è¨€è¯è¡¨è·¯å¾„: {src_vocab_path}")
            print(f"ğŸ“ ç›®æ ‡è¯­è¨€è¯è¡¨è·¯å¾„: {tgt_vocab_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜è¯è¡¨æ—¶å‡ºé”™: {e}")
            # å°è¯•ä¿å­˜åŸå§‹è¯è¡¨ä½œä¸ºå¤‡ä»½
            with open('src_vocab_backup.pkl', 'wb') as f:
                pickle.dump(src_vocab, f)
            with open('tgt_vocab_backup.pkl', 'wb') as f:
                pickle.dump(tgt_vocab, f)
            print("âš ï¸ å·²ä¿å­˜åŸå§‹è¯è¡¨å¤‡ä»½")


    # ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‡†ç¡®ç‡å˜åŒ–æ›²çº¿
    epochs_range = range(1, len(train_accuracies) + 1)
    
    plt.figure(figsize=(12, 4))
    
    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, train_accuracies, label='Training Accuracy', marker='o')
    plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', marker='o')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, train_losses, label='Training Loss', marker='o')
    plt.plot(epochs_range, val_losses, label='Validation Loss', marker='o')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig(os.path.join(project_root, 'training_curves.png'), dpi=300, bbox_inches='tight')

    print(f"\nâœ… ç¿»è¯‘è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
    return best_loss
