"""
ç¿»è¯‘ä»»åŠ¡è®­ç»ƒæ¨¡å—
"""
import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from model.full_transformer import Transformer
from data.translation_data import get_dataloaders
import pickle
import matplotlib.pyplot as plt


def calculate_accuracy(outputs, targets):
    """è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡"""
    with torch.no_grad():
        # è·å–é¢„æµ‹ç»“æœ
        predicted = outputs.argmax(dim=-1)
        # åˆ›å»ºæ©ç ï¼Œå¿½ç•¥å¡«å……å€¼ï¼ˆå‡è®¾å¡«å……å€¼ä¸º0ï¼‰
        mask = targets != 0
        # è®¡ç®—å‡†ç¡®ç‡
        correct = (predicted == targets) & mask
        accuracy = correct.sum().item() / mask.sum().item()
        return accuracy


def train_translation_epoch(model, dataloader, optimizer, criterion, device):
    """è®­ç»ƒç¿»è¯‘æ¨¡å‹ä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    total_acc = 0
    num_batches = 0

    for batch_idx, (src, tgt) in enumerate(dataloader):
        src, tgt = src.to(device), tgt.to(device)

        optimizer.zero_grad()
        
        # åœ¨è®­ç»ƒæ—¶ï¼Œç›®æ ‡åºåˆ—éœ€è¦ç§»ä½ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯
        tgt_input = tgt[:, :-1]  # é™¤æœ€åä¸€ä¸ªè¯
        tgt_output = tgt[:, 1:]  # ä»ç¬¬äºŒä¸ªè¯å¼€å§‹
        
        outputs = model(src, tgt_input)
        loss = criterion(outputs.view(-1, outputs.size(-1)), tgt_output.contiguous().view(-1))
        
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        # è®¡ç®—å‡†ç¡®ç‡
        acc = calculate_accuracy(outputs, tgt_output)
        total_acc += acc
        num_batches += 1

        if batch_idx % 50 == 0:
            print(f"  Batch {batch_idx}/{len(dataloader)} | Loss: {loss.item():.4f}")

    avg_loss = total_loss / len(dataloader)
    avg_acc = total_acc / num_batches if num_batches > 0 else 0
    return avg_loss, avg_acc


def evaluate_translation(model, dataloader, criterion, device):
    """è¯„ä¼°ç¿»è¯‘æ¨¡å‹"""
    model.eval()
    total_loss = 0
    total_acc = 0
    num_batches = 0

    with torch.no_grad():
        for src, tgt in dataloader:
            src, tgt = src.to(device), tgt.to(device)
            
            tgt_input = tgt[:, :-1]
            tgt_output = tgt[:, 1:]
            
            outputs = model(src, tgt_input)
            loss = criterion(outputs.view(-1, outputs.size(-1)), tgt_output.contiguous().view(-1))

            total_loss += loss.item()
            # è®¡ç®—å‡†ç¡®ç‡
            acc = calculate_accuracy(outputs, tgt_output)
            total_acc += acc
            num_batches += 1

    avg_loss = total_loss / len(dataloader)
    avg_acc = total_acc / num_batches if num_batches > 0 else 0
    return avg_loss, avg_acc


def train_translation_model(params):
    """è®­ç»ƒç¿»è¯‘æ¨¡å‹ä¸»å‡½æ•°"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    if not os.path.exists(params['data_dir']):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®ç›®å½• {params['data_dir']}")
        print("è¯·ç¡®ä¿ç¿»è¯‘æ•°æ®é›†å·²ä¸‹è½½å¹¶æ”¾ç½®åœ¨æ­£ç¡®ç›®å½•ä¸­")
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        from data.download_sample_data import prepare_data_for_training
        prepare_data_for_training()
        params['data_dir'] = 'data/multi30k'  # ä½¿ç”¨æ–°çš„æ•°æ®ç›®å½•

    # åŠ è½½ç¿»è¯‘æ•°æ®
    print("ğŸ“¥ åŠ è½½ç¿»è¯‘æ•°æ®...")
    train_loader, val_loader, test_loader, src_vocab, tgt_vocab = get_dataloaders(
        params['data_dir'],
        batch_size=params['batch_size'],
        max_len=params['max_seq_len'],
        src_lang=params['src_lang'],
        tgt_lang=params['tgt_lang']
    )
    
    if train_loader is None:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®")
        return float('inf')
    
    print(f"ğŸ”¤ æºè¯­è¨€è¯æ±‡è¡¨å¤§å°: {len(src_vocab)}")
    print(f"ğŸ”¤ ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°: {len(tgt_vocab)}")
    print(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset) if hasattr(train_loader, 'dataset') else len(train_loader) * params['batch_size']}")
    print(f"ğŸ“Š éªŒè¯é›†å¤§å°: {len(val_loader.dataset) if hasattr(val_loader, 'dataset') else len(val_loader) * params['batch_size']}")
    print(f"ğŸ“Š æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset) if hasattr(test_loader, 'dataset') else len(test_loader) * params['batch_size']}")

    # åˆå§‹åŒ–å®Œæ•´Transformeræ¨¡å‹
    model = Transformer(
        src_vocab_size=len(src_vocab),
        tgt_vocab_size=len(tgt_vocab),
        d_model=params['d_model'],
        num_heads=params['num_heads'],
        d_ff=params['d_model']*4,  # å‰é¦ˆç½‘ç»œç»´åº¦é€šå¸¸æ˜¯d_modelçš„4å€
        num_layers=params['num_layers'],
        dropout=params['dropout']
    ).to(device)

    print(f"ğŸ“Š ç¿»è¯‘æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # ä¼˜åŒ–å™¨ & æŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], betas=(0.9, 0.98), eps=1e-9)
    criterion = nn.CrossEntropyLoss(ignore_index=0)  # å¿½ç•¥å¡«å……å€¼

    # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []

    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    for epoch in range(1, params['epochs'] + 1):
        print(f"\nğŸš€ Epoch {epoch}/{params['epochs']}")
        print("-" * 30)

        # è®­ç»ƒ
        train_loss, train_acc = train_translation_epoch(model, train_loader, optimizer, criterion, device)
        print(f"ğŸ“ˆ Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)

        # éªŒè¯
        val_loss, val_acc = evaluate_translation(model, val_loader, criterion, device)
        print(f"ğŸ“‰ Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        # ä¿å­˜æœ€ä½³æ¨¡å‹å’Œè¯æ±‡è¡¨
        if val_loss < best_loss:
            best_loss = val_loss
            # ä¿å­˜æ¨¡å‹
            torch.save(model.state_dict(), params['model_save_path'])
            # åŒæ—¶ä¿å­˜è¯æ±‡è¡¨
            with open('src_vocab.pkl', 'wb') as f:
                pickle.dump(src_vocab, f)
            with open('tgt_vocab.pkl', 'wb') as f:
                pickle.dump(tgt_vocab, f)
            print(f"âœ¨ ç¿»è¯‘æ¨¡å‹å’Œè¯æ±‡è¡¨å·²ä¿å­˜ (Val Loss: {val_loss:.4f})")

    # ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‡†ç¡®ç‡å˜åŒ–æ›²çº¿
    epochs_range = range(1, len(train_accuracies) + 1)
    
    plt.figure(figsize=(12, 4))
    
    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, train_accuracies, label='Training Accuracy', marker='o')
    plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', marker='o')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, train_losses, label='Training Loss', marker='o')
    plt.plot(epochs_range, val_losses, label='Validation Loss', marker='o')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')

    print(f"\nâœ… ç¿»è¯‘è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
    return best_loss