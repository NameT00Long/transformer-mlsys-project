# test_model.py
import torch
from model.transformer import TransformerClassifier

def test_transformer_classifier():
    print("ğŸ” æµ‹è¯• TransformerClassifier...")
    
    # è¶…å‚æ•°
    vocab_size = 10000   # IMDb é€šå¸¸ç”¨ 10k è¯è¡¨
    d_model = 256
    batch_size = 4
    seq_len = 256
    
    # åˆ›å»ºæ¨¡å‹
    model = TransformerClassifier(
        vocab_size=vocab_size,
        d_model=d_model,
        nhead=4,
        num_layers=4,
        num_classes=2
    )
    
    # æ¨¡æ‹Ÿè¾“å…¥ï¼štoken IDs
    input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))  # [4, 256]
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():  # æµ‹è¯•æ—¶ä¸è®¡ç®—æ¢¯åº¦
        logits = model(input_ids)
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    assert logits.shape == (batch_size, 2), f"æœŸæœ› (4, 2)ï¼Œå¾—åˆ° {logits.shape}"
    print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æˆåŠŸï¼")
    print(f"  è¾“å…¥å½¢çŠ¶: {input_ids.shape}")
    print(f"  è¾“å‡ºå½¢çŠ¶: {logits.shape}")
    print(f"  è¾“å‡ºç¤ºä¾‹: {logits[0].tolist()}")

if __name__ == "__main__":
    test_transformer_classifier()