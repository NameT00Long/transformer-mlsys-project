"""
ä¸‹è½½å’Œå‡†å¤‡è®­ç»ƒæ•°æ®çš„æ¨¡å—
"""
import os
from datasets import load_dataset, load_from_disk


def prepare_data_for_training():
    """ä¸‹è½½å¹¶å‡†å¤‡Multi30kæ•°æ®ç”¨äºè®­ç»ƒ"""
    print("ğŸ“¥ å¼€å§‹ä¸‹è½½Multi30kæ•°æ®é›†...")
    
    try:
        # ä½¿ç”¨Hugging Face datasetsåŠ è½½Multi30kæ•°æ®é›†
        # Multi30kæ•°æ®é›†åŒ…å«è‹±è¯­åˆ°å¾·è¯­ã€è‹±è¯­åˆ°æ³•è¯­ç­‰ç¿»è¯‘ä»»åŠ¡
        dataset = load_dataset("bentrevett/multi30k")
        
        print("âœ… Multi30kæ•°æ®é›†ä¸‹è½½å®Œæˆ!")
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   è®­ç»ƒé›†å¤§å°: {len(dataset['train'])}")
        print(f"   éªŒè¯é›†å¤§å°: {len(dataset['validation'])}")
        print(f"   æµ‹è¯•é›†å¤§å°: {len(dataset['test'])}")
        
        # æ£€æŸ¥æ•°æ®é›†ç»“æ„å¹¶å¤„ç†ä¸åŒçš„åˆ—åæ ¼å¼
        train_sample = dataset['train'][0]
        print(f"   ç¤ºä¾‹æ•°æ®: {train_sample}")
        
        # æ ¹æ®Multi30kæ•°æ®é›†çš„å®é™…ç»“æ„ï¼Œç¡®å®šæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€åˆ—å
        src_lang, tgt_lang = get_language_columns(dataset)
        print(f"   æ£€æµ‹åˆ°æºè¯­è¨€åˆ—: {src_lang}")
        print(f"   æ£€æµ‹åˆ°ç›®æ ‡è¯­è¨€åˆ—: {tgt_lang}")
        
        # åˆ›å»ºæ•°æ®ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs('data/multi30k', exist_ok=True)
        
        # ä¿å­˜æ•°æ®é›†åˆ°ç£ç›˜
        dataset.save_to_disk('data/multi30k/dataset')
        print("ğŸ’¾ æ•°æ®é›†å·²ä¿å­˜åˆ° data/multi30k/dataset")
        
        # ä¿å­˜è¯­è¨€é…ç½®
        with open('data/multi30k/lang_config.txt', 'w') as f:
            f.write(f"{src_lang},{tgt_lang}")
        print(f"ğŸ’¾ è¯­è¨€é…ç½®å·²ä¿å­˜åˆ° data/multi30k/lang_config.txt")
        
        print("ğŸ’¡ æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨Hugging Face datasetsè¿›è¡Œè®­ç»ƒ")
        
        return src_lang, tgt_lang
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…datasetsåº“: pip install datasets")
        return None, None


def get_language_columns(dataset):
    """
    æ ¹æ®æ•°æ®é›†ç»“æ„ç¡®å®šæºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„åˆ—å
    Multi30kæ•°æ®é›†é€šå¸¸ä»¥å­—å…¸å½¢å¼å­˜å‚¨ç¿»è¯‘å¯¹
    """
    sample = dataset['train'][0]
    
    # ç›´æ¥æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡å‡†çš„en/deåˆ—å
    if 'en' in sample and 'de' in sample:
        return 'en', 'de'
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«translationå­—æ®µ
    if 'translation' in sample:
        translation_dict = sample['translation']
        keys = list(translation_dict.keys())
        
        # ç¡®ä¿è‡³å°‘æœ‰ä¸¤ç§è¯­è¨€
        if len(keys) >= 2:
            # ä¼˜å…ˆé€‰æ‹©è‹±è¯­å’Œå¾·è¯­
            if 'en' in keys and 'de' in keys:
                return 'en', 'de'
            # å¦‚æœæ²¡æœ‰è‹±è¯­å’Œå¾·è¯­ï¼Œä½¿ç”¨å‰ä¸¤ç§è¯­è¨€
            else:
                return keys[0], keys[1]
    
    # å¦‚æœä»¥ä¸Šéƒ½ä¸åŒ¹é…ï¼Œæ‰“å°æ›´å¤šæ•°æ®æ ·æœ¬ä»¥å¸®åŠ©è°ƒè¯•
    print(f"âš ï¸  æ— æ³•è‡ªåŠ¨æ£€æµ‹è¯­è¨€åˆ—åï¼Œæ•°æ®ç»“æ„: {sample}")
    print("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®é›†æ ¼å¼å¹¶ç›¸åº”åœ°è°ƒæ•´ä»£ç ")
    
    # é»˜è®¤è¿”å›en/deï¼Œä½†å®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®å…·ä½“æ•°æ®æ ¼å¼è°ƒæ•´
    return 'en', 'de'


def load_prepared_dataset():
    """åŠ è½½å·²å‡†å¤‡çš„æ•°æ®é›†"""
    dataset_path = 'data/multi30k/dataset'
    lang_config_path = 'data/multi30k/lang_config.txt'
    
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        print(f"âš ï¸  æ•°æ®é›†ä¸å­˜åœ¨äº {dataset_path}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ prepare_data_for_training() ä¸‹è½½æ•°æ®é›†")
        return None, None, None
    
    try:
        # ä»ç£ç›˜åŠ è½½æ•°æ®é›†
        dataset = load_from_disk(dataset_path)
        
        # åŠ è½½è¯­è¨€é…ç½®
        with open(lang_config_path, 'r') as f:
            src_lang, tgt_lang = f.read().strip().split(',')
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   æºè¯­è¨€: {src_lang}")
        print(f"   ç›®æ ‡è¯­è¨€: {tgt_lang}")
        
        return dataset, src_lang, tgt_lang
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†æ—¶å‡ºé”™: {e}")
        return None, None, None


def check_dataset_format():
    """æ£€æŸ¥æ•°æ®é›†æ ¼å¼å¹¶æä¾›ä¿¡æ¯"""
    print("ğŸ” æ£€æŸ¥Multi30kæ•°æ®é›†æ ¼å¼...")
    try:
        # åŠ è½½å°éƒ¨åˆ†æ•°æ®è¿›è¡Œæ ¼å¼æ£€æŸ¥
        dataset = load_dataset("bentrevett/multi30k", split='train[:5]')  # åªåŠ è½½å‰5ä¸ªæ ·æœ¬
        print(f"   æ•°æ®é›†åˆ—å: {dataset.column_names}")
        print(f"   æ ·æœ¬æ•°æ®: {dataset[0]}")
    except Exception as e:
        print(f"   æ£€æŸ¥æ•°æ®é›†æ ¼å¼æ—¶å‡ºé”™: {e}")


# æ·»åŠ å‡½æ•°è°ƒç”¨ä»¥æ‰§è¡Œæ•°æ®å‡†å¤‡
if __name__ == "__main__":
    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists('data/multi30k/dataset'):
        print("ğŸ“‚ æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        dataset, src_lang, tgt_lang = load_prepared_dataset()
    else:
        src_lang, tgt_lang = prepare_data_for_training()
